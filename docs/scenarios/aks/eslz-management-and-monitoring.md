---
title: "Enterprise-Scale management and monitoring for AKS"
description: Describe how this enterprise-scale scenario can improve management and monitoring of AKS
author: Pieter de Bruin
ms.author: pidebrui
ms.date: 10/12/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: ready
---

# Management and monitoring for AKS Enterprise-Scale scenario
Kubernetes is a relatively young technology, rapidly evolving and has an impressive ecosystem. As such it can be a challenge to manage it. By properly designing the solution with management and monitoring in mind, you can work towards operational excellence and customer success.

## Design considerations
Consider the following factors:

* Be aware of AKS limits. Use multiple AKS instances to scale beyond those limits.
* Be aware of ways to isolate workloads logically within a cluster and physically in separate clusters.
* Be aware of ways to control resource consumption by workloads.
* Be aware of ways to help Kubernetes understand the health of your workloads.
* Be aware of various virtual machines sizes and the impact of using one or the other. Larger VMs can handle more load. Smaller VMs can easier be replaced by others when unavailable for planned and unplanned maintenance. Also be aware of the concept of node pools, VMs in a scale set, which allows to have virtual machines of a different size in the same cluster.
* Be aware of ways to monitor and log AKS. Kubernetes consists of various components and monitoring and logging should provide an insight of its health, trends as well as potential issues.
* Building on monitoring and logging there can be many events generated by Kubernetes or applications running on top. Alerts can help differentiate between log entries for historical purposes and those that require immediate action.
* Be aware of updates and upgrades that you should do. At the Kubernetes level there are major, minor and patch versions. The customer should apply these update, to remain in a supported state according to the policy in upstream Kubernetes. At the worker host level OS kernel patches may require a reboot, which the customer should do, as well as upgrades to new OS versions.
* Be aware of resource limitations of the cluster as well as individual workloads.
* Monitor for the use of best practices.
* Be aware of options to manage multiple clusters with Azure as well as Kubernetes certified clusters outside of Azure.

## Design recommendations
* Understand AKS limits:
  * [Qutas and regional limits](https://docs.microsoft.com/azure/aks/quotas-skus-regions)
  * [AKS service limits](https://docs.microsoft.com/azure/azure-resource-manager/management/azure-subscription-service-limits#azure-kubernetes-service-limits)
* Use logical isolation at the namespace level to separate applications, teams, environments, business units. [Multi-tenancy and cluster isolation](https://docs.microsoft.com/azure/aks/operator-best-practices-cluster-isolation). Also nodepools can help at nodes with different node specifications, and maintenance like Kubernetes upgrades [Multiple Node Pools](https://docs.microsoft.com/azure/aks/use-multiple-node-pools)
* Plan and apply resource quotas at the namespace level. If pods don't define resource requests and limits, reject the deployment. Monitor resource usage and adjust quotas as needed. [Basic scheduler features](https://docs.microsoft.com/azure/aks/operator-best-practices-scheduler)
* Add Health Probes to your services. Make sure pods contain  Liveness, Readiness, and Startup probes. [AKS Health Probes](https://docs.microsoft.com/azure/application-gateway/ingress-controller-add-health-probes)
* Use VM sizes that are big enough, to contain multiple container instances so you get the benefits of increased density, and not too big, so that your cluster can handle the workload of a failing node.
* Use a monitoring solution. Azure monitor works by default and provides easy access to many insights. [Azure Container Insights](https://docs.microsoft.com/azure/azure-monitor/insights/container-insights-overview) If you want to drill deeper or are experienced with Prometheus use that. [Prometheus Integration](https://docs.microsoft.com/azure/azure-monitor/insights/container-insights-prometheus-integration)
Note that if you want to run a monitoring application on AKS, you also want to look at Azure monitor to monitor that app.
* Use an alerting system to provide notifications when things need direct action. [Metric alerts](https://docs.microsoft.com/azure/azure-monitor/insights/container-insights-metric-alerts)
* Use [Kured](https://docs.microsoft.com/azure/aks/node-updates-kured) for node updates. Upgrade worker nodes [Node upgrades](https://docs.microsoft.com/azure/aks/node-image-upgrade)
* Use [Automatic Node Pool Scaling](https://docs.microsoft.com/azure/aks/cluster-autoscaler) feature together with [Horizontal Pod Autoscaler](https://docs.microsoft.com/azure/aks/concepts-scale#horizontal-pod-autoscaler) to meet application demands and to mitigate peak hours loads.
* Use Azure Advisor to get best practice recommendations on cost, security, reliability, operational excellence and performance. Also use [Security Center](https://docs.microsoft.com/azure/security-center/azure-kubernetes-service-integration) to prevent and detect threats like image vulnerabilities.
* Use [Azure Arc](https://docs.microsoft.com/azure/azure-arc/kubernetes/overview) enabled Kubernetes to manage non-AKS Kubernetes clusters in Azure using Azure Policy, Security Center, GitOps, etc.
